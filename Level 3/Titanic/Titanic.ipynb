{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9fd625a-476c-4870-bcd1-14dac4eea09a",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction - Project Overview\n",
    "\n",
    "**Goal**: Predict whether a passenger survived the Titanic shipwreck.\n",
    "\n",
    "**Type**: Binary Classification  \n",
    "**Input**: Passenger information (age, class, gender, etc.)  \n",
    "**Output**: Survived (1) or Not Survived (0)\n",
    "\n",
    "We will cover:\n",
    "- Data exploration and cleaning\n",
    "- Feature engineering (e.g., titles from names)\n",
    "- Handling missing values\n",
    "- Model training and evaluation\n",
    "- Improving performance with tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8451555c-bf40-4235-a393-bb107704e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1b4c3f0-83aa-4a55-becf-fe19a54302ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\Real ML\\Level 3\\titanic\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b31183-03f0-422c-81d7-dfe7476b385b",
   "metadata": {},
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efb4dc9e-ee0b-4bf1-ab47-0a41ef33a71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (891, 12)\n",
      "\n",
      "Column Names:\n",
      " ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nColumn Names:\\n\", df.columns.tolist())\n",
    "df.describe()\n",
    "\n",
    "df.isnull().sum()\n",
    "df['Survived'].value_counts(normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e0d537-c80d-43c4-a031-47766e76e19e",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75aecb7f-3e0b-437a-8d8d-84fadd7fcac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns only if they exist\n",
    "cols_to_drop = ['PassengerId', 'Ticket', 'Cabin']\n",
    "df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "# Fill missing values safely\n",
    "if 'Age' in df.columns:\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "if 'Embarked' in df.columns:\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "\n",
    "# Extract Title from Name (if Name exists), then drop Name\n",
    "if 'Name' in df.columns:\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    df.drop(columns='Name', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89acbde8-a088-4257-b773-04247c82efb9",
   "metadata": {},
   "source": [
    "Categorical Encoding and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd1c231e-dea3-4337-86c6-056410fbe8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Title',\n",
      "       'Embarked_Q', 'Embarked_S', 'FamilySize'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Title  Embarked_Q  \\\n",
      "0         0       3    0  22.0      1      0   7.2500      0       False   \n",
      "1         1       1    1  38.0      1      0  71.2833      2       False   \n",
      "2         1       3    1  26.0      0      0   7.9250      1       False   \n",
      "3         1       1    1  35.0      1      0  53.1000      2       False   \n",
      "4         0       3    0  35.0      0      0   8.0500      0       False   \n",
      "\n",
      "   Embarked_S  FamilySize  \n",
      "0        True           2  \n",
      "1       False           2  \n",
      "2        True           1  \n",
      "3        True           2  \n",
      "4        True           1  \n"
     ]
    }
   ],
   "source": [
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "# Replace rare titles with 'Rare'\n",
    "df['Title'] = df['Title'].replace(\n",
    "    ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', \n",
    "     'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "# Normalize similar titles\n",
    "df['Title'] = df['Title'].replace({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})\n",
    "\n",
    "# Encode titles\n",
    "title_mapping = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Rare': 4}\n",
    "df['Title'] = df['Title'].map(title_mapping).astype(int)\n",
    "\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95beac34-3601-4ee7-9179-7356a70a1ff1",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bd34108-743b-4e88-8004-092365c4c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select features (drop target column)\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69739e07-4570-433f-b0b0-12a382c624a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18388307-4508-4f28-b827-f04fdefd30c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7877094972067039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       105\n",
      "           1       0.74      0.74      0.74        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b9dd3-b3b4-4ba5-832d-d9760fee1cf8",
   "metadata": {},
   "source": [
    "Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29bf8f0b-d530-4bf8-a396-585fe89f2c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Accuracy: 0.7821229050279329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       105\n",
      "           1       0.74      0.73      0.73        74\n",
      "\n",
      "    accuracy                           0.78       179\n",
      "   macro avg       0.78      0.77      0.77       179\n",
      "weighted avg       0.78      0.78      0.78       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create model\n",
    "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']  # 'liblinear' supports both l1 and l2\n",
    "}\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_logreg = grid_search.best_estimator_\n",
    "\n",
    "# Predict\n",
    "y_pred_best = best_logreg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ea8c5-7465-452e-92d5-91ccc408a095",
   "metadata": {},
   "source": [
    "Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "291972a4-0629-4f6b-8e58-4ba8a7f3485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.776536312849162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       105\n",
      "           1       0.73      0.73      0.73        74\n",
      "\n",
      "    accuracy                           0.78       179\n",
      "   macro avg       0.77      0.77      0.77       179\n",
      "weighted avg       0.78      0.78      0.78       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize and train\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fab9467-8516-4549-befb-401e8f403770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8268156424581006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       105\n",
      "           1       0.81      0.76      0.78        74\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.82      0.82      0.82       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63a8a723-c35f-44eb-bf17-839fccfe0eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8212290502793296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       105\n",
      "           1       0.80      0.76      0.78        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train\n",
    "svm_clf = SVC(kernel='rbf', C=1, gamma='scale')  # You can tune these later\n",
    "svm_clf.fit(X_train, y_train)  # Important: scale your features\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54f3cd9c-5b3d-4a5a-a60f-a60bfabbb520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_titanic.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model (Random Forest in this case)\n",
    "joblib.dump(rf_clf, 'random_forest_titanic.pkl')\n",
    "\n",
    "# To load it later\n",
    "# loaded_model = joblib.load('random_forest_titanic.pkl')\n",
    "# loaded_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4910dca-9d47-4793-87fe-d6607634b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.8100558659217877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       105\n",
      "           1       0.79      0.73      0.76        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate base models\n",
    "log_clf = LogisticRegression(C=0.1, penalty='l2', solver='liblinear', random_state=42)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "# Create the ensemble using hard voting (majority vote)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rf_clf), ('svm', svm_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0c3aec3-71ed-4b0a-86bc-7276b5e3a1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting Accuracy: 0.8212290502793296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ensemble_softvoting_titanic.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rf_clf), ('svm', svm_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "\n",
    "y_pred_soft = voting_clf_soft.predict(X_test)\n",
    "print(\"Soft Voting Accuracy:\", accuracy_score(y_test, y_pred_soft))\n",
    "\n",
    "joblib.dump(voting_clf_soft, 'ensemble_softvoting_titanic.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [ml-gpu]",
   "language": "python",
   "name": "ml-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
